{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a624b-850f-4b7c-85f5-3d6a54226645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login form found, logging in...\n",
      "Total number of details links: 22\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time  # for adding explicit waits\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import pandas as pd\n",
    "import traceback\n",
    "# pip install lxml\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize the WebDriver and set the window size\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.set_window_size(1903, 1015)  # Set the window size as per your IDE script\n",
    "\n",
    "# Step 1: Open the login page\n",
    "driver.get(\"https://app.courtreserve.com/Online/Account/LogIn/10688\")\n",
    "\n",
    "# Step 2: Check if the login form is present (i.e., you're not already logged in)\n",
    "try:\n",
    "    # Attempt to find the username field\n",
    "    username_field = driver.find_element(By.ID, \"UserNameOrEmail\")\n",
    "    \n",
    "    # If found, log in\n",
    "    username_field.send_keys(\"mohit.dhawan@tetracap.com\")\n",
    "    driver.find_element(By.ID, \"Password\").send_keys(\"123abc321\")\n",
    "    driver.find_element(By.CSS_SELECTOR, \".btn-log\").click()\n",
    "    \n",
    "    print(\"Login form found, logging in...\")\n",
    "    \n",
    "    # Wait for login to complete\n",
    "    time.sleep(10)\n",
    "\n",
    "except Exception as e:\n",
    "    # If login form is not found, you may already be logged in\n",
    "    print(\"Login form not found, assuming already logged in...\")\n",
    "\n",
    "# Step 3: Navigate directly to the reservations page\n",
    "driver.get(\"https://app.courtreserve.com/Online/Reservations/Index/10688\")\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "page_source = driver.page_source\n",
    "# print(page_source)\n",
    "\n",
    "with open('page_source.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(page_source)\n",
    "    \n",
    "\n",
    "soup = BeautifulSoup(page_source,'lxml')\n",
    "details_links = soup.find_all('a', class_='btn-scheduler-details')\n",
    "base_url = \"https://app.courtreserve.com\"\n",
    "\n",
    "total_links = len(details_links)\n",
    "print(f\"Total number of details links: {total_links}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c32df81-3035-43ff-a019-cb98fd21ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Online/Events/Details/10688/VPQWM9Q10688283\n",
      "Completed 1/22\n",
      "Processing: /Online/Events/Details/10688/8TMTFQ210688290\n",
      "Completed 2/22\n",
      "Processing: /Online/Events/Details/10688/A9RZLET10688852\n",
      "Completed 3/22\n",
      "Processing: /Online/Events/Details/10688/95QBDCK10688130\n",
      "Completed 4/22\n",
      "Processing: /Online/Events/Details/10688/L6XGIW210688322\n",
      "Completed 5/22\n",
      "Processing: /Online/Events/Details/10688/D8QDNKT10688547\n",
      "Completed 6/22\n",
      "Processing: /Online/Events/Details/10688/8TMTFQ210688290\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/8TMTFQ210688290\n",
      "Processing: /Online/Events/Details/10688/L6XGIW210688322\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/L6XGIW210688322\n",
      "Processing: /Online/Events/Details/10688/8TMTFQ210688290\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/8TMTFQ210688290\n",
      "Processing: /Online/Events/Details/10688/L6XGIW210688322\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/L6XGIW210688322\n",
      "Processing: /Online/Events/Details/10688/8TMTFQ210688290\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/8TMTFQ210688290\n",
      "Processing: /Online/Events/Details/10688/L6XGIW210688322\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/L6XGIW210688322\n",
      "Processing: /Online/Events/Details/10688/8TMTFQ210688290\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/8TMTFQ210688290\n",
      "Processing: /Online/Events/Details/10688/L6XGIW210688322\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/L6XGIW210688322\n",
      "Processing: /Online/Events/Details/10688/8TMTFQ210688290\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/8TMTFQ210688290\n",
      "Processing: /Online/Events/Details/10688/RDDBKBK10688750\n",
      "Completed 16/22\n",
      "Processing: /Online/Events/Details/10688/L6XGIW210688322\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/L6XGIW210688322\n",
      "Processing: /Online/Events/Details/10688/8TMTFQ210688290\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/8TMTFQ210688290\n",
      "Processing: /Online/Events/Details/10688/RDDBKBK10688750\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/RDDBKBK10688750\n",
      "Processing: /Online/Events/Details/10688/L6XGIW210688322\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/L6XGIW210688322\n",
      "Processing: /Online/Events/Details/10688/8TMTFQ210688290\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/8TMTFQ210688290\n",
      "Processing: /Online/Events/Details/10688/L6XGIW210688322\n",
      "Skipping already visited URL: https://app.courtreserve.com/Online/Events/Details/10688/L6XGIW210688322\n"
     ]
    }
   ],
   "source": [
    "data_list=[]\n",
    "visited_urls = set()\n",
    "# Loop through each event (assuming the loop for different events is outside)\n",
    "for i, link in enumerate(details_links):\n",
    "    try:\n",
    "        # Step 1: Get href and construct full URL\n",
    "        href = link.get('href')\n",
    "        full_url = base_url + href\n",
    "        print(f\"Processing: {href}\")\n",
    "        # Check if the full_url has already been visited\n",
    "        if full_url in visited_urls:\n",
    "            print(f\"Skipping already visited URL: {full_url}\")\n",
    "            continue  # Skip to the next link\n",
    "        \n",
    "        # Mark this URL as visited\n",
    "        visited_urls.add(full_url)\n",
    "        # Navigate to the full URL\n",
    "        driver.get(full_url)\n",
    "        \n",
    "        # Wait for the page to load fully\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Get the page source and parse it using BeautifulSoup\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "        \n",
    "        # 1. Extract the title (h4 tag)\n",
    "        title = soup.find('h4').get_text(strip=True)\n",
    "        \n",
    "        # 2. Extract all elements with class 'title-part'\n",
    "        title_parts = soup.find_all('span', class_='title-part')\n",
    "        \n",
    "        # Extract date, time, fees, and participant count\n",
    "        date = title_parts[0].get_text(strip=True) if len(title_parts) > 0 else 'N/A'\n",
    "        time_info = title_parts[1].get_text(strip=True) if len(title_parts) > 1 else 'N/A'\n",
    "        fees = title_parts[2].get_text(strip=True) if len(title_parts) > 2 else 'N/A'\n",
    "        participant_count = title_parts[3].get_text(strip=True) if len(title_parts) > 3 else 'N/A'\n",
    "        \n",
    "        # Concatenate any additional title-part elements beyond the first four\n",
    "        additional_info = \" \".join([part.get_text(strip=True) for part in title_parts[4:]]) if len(title_parts) > 4 else 'N/A'\n",
    "        \n",
    "        # Extract coach name\n",
    "        instructor_label = soup.find('p', string='Instructor(s)')\n",
    "        coach = instructor_label.find_next_sibling('p').get_text(strip=True) if instructor_label else 'N/A'\n",
    "\n",
    "        # Extract court information\n",
    "        court_label = soup.find('p', string='Court(s)')\n",
    "        court = court_label.find_next_sibling('p').get_text(strip=True) if court_label else 'N/A'\n",
    "        \n",
    "        # Extract registrants information\n",
    "        registrants_element = soup.find('span', class_='k-link', string=lambda text: 'REGISTRANTS' in text)\n",
    "        registrants_text = registrants_element.get_text(strip=True) if registrants_element else 'N/A'\n",
    "        \n",
    "        # Extract the number of registrants from the text\n",
    "        import re\n",
    "        registrants_count = re.search(r'\\((\\d+)\\)', registrants_text)\n",
    "        registrants_count = registrants_count.group(1) if registrants_count else 'N/A'\n",
    "        \n",
    "        # Append the data to the list\n",
    "        data_list.append({\n",
    "            'Title': title,\n",
    "            'Date': date,\n",
    "            'Time': time_info,\n",
    "            'Fees': fees,\n",
    "            'Info': participant_count,\n",
    "            'AdditionalInfo': additional_info,\n",
    "            'Coach': coach,\n",
    "            'Court': court,\n",
    "            'Registrants': registrants_count\n",
    "        })\n",
    "        \n",
    "        # Go back to the reservations page to process the next link\n",
    "        driver.back()\n",
    "        time.sleep(4)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Completed {i + 1}/{total_links}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Print out the error and continue with the next iteration\n",
    "        print(f\"Error occurred: {e}, {full_url}\")\n",
    "        traceback.print_exc()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8f5259-f9b7-43bb-b15d-cbb16d278fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Regular expressions for extracting date and time\n",
    "date_regex = r'([A-Za-z]{3} \\d{1,2})'  # Matches the month and day, e.g., \"Aug 21\"\n",
    "time_regex = r'(\\d{2}:\\d{2})'  # Matches the time, e.g., \"16:00\"\n",
    "# data_list=[]\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "reserve_buttons = soup.find_all('button', string=\"Reserve\")\n",
    "\n",
    "for button in reserve_buttons:\n",
    "    try:\n",
    "        if 'hide' not in button.get('class', []):\n",
    "            # Extracting the attributes of the button (like start time, end time, etc.)\n",
    "            start_time = button.get('start')\n",
    "            end_time = button.get('end')\n",
    "            court_label = button.get('courtlabel')\n",
    "\n",
    "            # Apply regular expressions to extract date and time\n",
    "            if start_time and end_time:\n",
    "                # Extract date from start_time\n",
    "                date_match = re.search(date_regex, start_time)\n",
    "                date = date_match.group(0) if date_match else \"N/A\"\n",
    "\n",
    "                # Extract time from start_time and end_time\n",
    "                start_time_match = re.search(time_regex, start_time)\n",
    "                end_time_match = re.search(time_regex, end_time)\n",
    "\n",
    "                if start_time_match and end_time_match:\n",
    "                    # Convert 24-hour time to simplified \"p/a\" format\n",
    "                    start_dt = datetime.strptime(start_time_match.group(0), '%H:%M')\n",
    "                    end_dt = datetime.strptime(end_time_match.group(0), '%H:%M')\n",
    "                    start_time_str = start_dt.strftime('%I').lstrip('0') + start_dt.strftime('%p').lower()[0]\n",
    "                    end_time_str = end_dt.strftime('%I').lstrip('0') + end_dt.strftime('%p').lower()[0]\n",
    "                    time_range = f\"{start_time_str}-{end_time_str}\"\n",
    "                else:\n",
    "                    time_range = \"N/A\"\n",
    "            else:\n",
    "                date = \"N/A\"\n",
    "                time_range = \"N/A\"\n",
    "\n",
    "            # Assuming Title = \"Open\", Fees = $0, Registrants = 0, Participant Count = 0\n",
    "            title = \"Open\"\n",
    "            fees = 0\n",
    "            registrants_count = 0\n",
    "            participant_count = 0\n",
    "\n",
    "            # Append the data to the list\n",
    "            data_list.append({\n",
    "                'Title': title,\n",
    "                'Date': date,  # Extracted date using regex\n",
    "                'Time': time_range,  # Extracted and formatted time range\n",
    "                'Fees': fees,\n",
    "                'Info': participant_count,\n",
    "                'AdditionalInfo': \"None\",  # Placeholder for additional info if needed\n",
    "                'Coach': \"None\",  # Assuming no coach for open courts\n",
    "                'Court': court_label,\n",
    "                'Registrants': registrants_count\n",
    "            })\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that occur during the process\n",
    "        print(f\"Error processing button: {e}\")\n",
    "        continue  # Skip this button and move to the next one\n",
    "# Step 7: Convert the data into a DataFrame and display/save it\n",
    "df = pd.DataFrame(data_list)\n",
    "# print(df)\n",
    "\n",
    "# Save the data to a CSV file if needed\n",
    "# df.to_csv('open_courts_reservation_info.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b89183b-b278-488a-8a3d-eaa5bf9cb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries to a DataFrame using pandas\n",
    "df = pd.concat([pd.DataFrame([data]) for data in data_list], ignore_index=True)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "\n",
    "\n",
    "# Get the current date in the desired format\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Construct the filename with the date\n",
    "filename = f'reservation_data_{current_date}.csv'\n",
    "\n",
    "# Save the DataFrame to CSV with the date in the filename\n",
    "df.to_csv(filename, index=False)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a7dc8-fffe-4453-b395-a7e1831ffa28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
